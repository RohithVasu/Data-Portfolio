{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42350fcb-42e2-43d7-9de1-80dd58372eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GEMINI_API_KEY'] = '*******'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8858982b-f7d5-4b92-a4d4-1d6ff3b9bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_data(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        sample_data = json.load(f)\n",
    "\n",
    "    content = []\n",
    "    \n",
    "    for data in sample_data['data']:\n",
    "        for paragraph in data['paragraphs']:\n",
    "            content.append(paragraph['context'])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e459603-8bbc-448b-8b7a-5755a72461d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = read_data('dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d05aca-105f-43ef-826b-8eef6c71ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "def embed_and_load(content):\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name = 'sentence-transformers/all-mpnet-base-v2')\n",
    "    db = Chroma.from_texts(content, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c685d99-2b0a-4246-9db3-2563a88c6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/rohith_vasu/Library/Python/3.12/lib/python/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db = embed_and_load(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d599b6f0-35f8-47b6-8a06-97ee6813e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_data(query, db):\n",
    "  passage = db.similarity_search(query = query)\n",
    "  return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9023943-5194-4e7a-ab39-f183c123ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_prompt(query, relevant_passage):\n",
    "  prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "  strike a friendly and converstional tone. \\\n",
    "  If the passage is irrelevant to the answer, you may ignore it.\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "  ANSWER:\n",
    "  \"\"\").format(query = query, relevant_passage = relevant_passage)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67f5476-3612-4eb0-9620-069c10faada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def generate_answer(prompt):\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    genai.configure(api_key = gemini_api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    answer = model.generate_content(prompt)\n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25aac14e-ce04-410f-b671-cb5de501678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_answer(db,query):\n",
    "    relevant_text = get_relevant_data(query,db)\n",
    "    prompt = make_rag_prompt(query, relevant_passage = relevant_text)\n",
    "    answer = generate_answer(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c8d6a4-1f81-4e42-a780-25b445a330d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Turing machine is a theoretical mathematical model that broadly represents any computing machine - even including a human with pencil and paper! They are used in computer science to study and solve problems that might arise in any type of computation scenario.\n"
     ]
    }
   ],
   "source": [
    "answer = final_answer(db = db,query = \"What is the scientific model of a general computing machine?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961b1a8-86a5-4e87-a49b-e6fb5e07ebcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
